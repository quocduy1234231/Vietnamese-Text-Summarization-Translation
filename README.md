# ğŸ§  Machine Translation & Reinforcement Learning for NLP  
Má»™t dá»± Ã¡n cÃ¡ nhÃ¢n nghiÃªn cá»©u vá» **dá»‹ch mÃ¡y (EN â†’ VI)** vÃ  **á»©ng dá»¥ng Reinforcement Learning** trong mÃ´ hÃ¬nh ngÃ´n ngá»¯.

Dá»± Ã¡n bao gá»“m:
- XÃ¢y dá»±ng vÃ  so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh *Transformer* vÃ  *GPT* cho bÃ i toÃ¡n dá»‹ch Anh â†’ Viá»‡t.
- TÃ¬m hiá»ƒu cÃ¡c thuáº­t toÃ¡n RL hiá»‡n Ä‘áº¡i nhÆ° **PPO, TRPO, A2C, SAC** vÃ  cÃ¡ch chÃºng Ä‘Æ°á»£c á»©ng dá»¥ng Ä‘á»ƒ tá»‘i Æ°u mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs).
- Thá»±c nghiá»‡m, Ä‘Ã¡nh giÃ¡, vÃ  phÃ¢n tÃ­ch káº¿t quáº£ báº±ng BLEU & ROUGE.

---

## ğŸš€ Má»¥c tiÃªu dá»± Ã¡n
- XÃ¢y dá»±ng pipeline hoÃ n chá»‰nh cho bÃ i toÃ¡n Machine Translation.
- So sÃ¡nh **pre-trained vs. training-from-scratch** trÃªn cáº£ Transformer vÃ  GPT.
- KhÃ¡m phÃ¡ vai trÃ² cá»§a RL trong tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh sinh vÄƒn báº£n.
- Tá»‘i Æ°u cháº¥t lÆ°á»£ng dá»‹ch qua cÃ¡c ká»¹ thuáº­t attention vÃ  tokenization (BPE).

---

## ğŸ“Š Dataset

Dá»¯ liá»‡u cá»§a dá»± Ã¡n Ä‘Æ°á»£c tá»•ng há»£p tá»«:
- Nguá»“n song ngá»¯ **OPUS**
- Táº­p cÃ¢u bá»• sung sinh báº±ng mÃ´ hÃ¬nh Gemini
- Xá»­ lÃ½ vÃ  chuáº©n hÃ³a báº±ng:
  - Tokenization  
  - Byte Pair Encoding (BPE)  
  - Padding / Truncation  
  - TÃ¡ch Train â€“ Validation â€“ Test  

Hai táº­p dá»¯ liá»‡u chÃ­nh:
en_sents_dataset.txt
vi_sents_dataset.txt
---

## ğŸ—ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng

### ğŸ”¹ Transformer
- Kiáº¿n trÃºc Encoderâ€“Decoder Ä‘áº§y Ä‘á»§
- Multi-Head Self-Attention  
- Masked Attention cho Decoder  
- Pre-trained + Fine-tuning  
- Huáº¥n luyá»‡n tá»« Ä‘áº§u (baseline)

### ğŸ”¹ GPT (Decoder-only Transformer)
- Masked Multi-Head Attention  
- Dá»± Ä‘oÃ¡n token tiáº¿p theo (Causal LM)
- GPT-2 Fine-tuning
- GPT training from scratch

---

## ğŸ§ª Thá»±c nghiá»‡m & Káº¿t quáº£

4 mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡:

| MÃ´ hÃ¬nh | BLEU | ROUGE-1 | ROUGE-2 | ROUGE-L | Nháº­n xÃ©t |
|--------|------|----------|----------|-----------|---------|
| **Transformer (Pre-trained)** | Cao nháº¥t | âœ” | âœ” | âœ” | á»”n Ä‘á»‹nh, dá»‹ch tá»‘t |
| Transformer (Scratch) | Tháº¥p hÆ¡n | â€“ | â€“ | â€“ | Cáº§n dá»¯ liá»‡u lá»›n hÆ¡n |
| **GPT (Pre-trained)** | Tá»‘t | âœ” | âœ” | âœ” | CÃ¢u dá»‹ch mÆ°á»£t vÃ  tá»± nhiÃªn |
| GPT (Scratch) | Tháº¥p | â€“ | â€“ | â€“ | KhÃ³ há»c do dá»¯ liá»‡u háº¡n cháº¿ |

ğŸ‘‰ *MÃ´ hÃ¬nh máº¡nh nháº¥t:* **Transformer Pre-trained** vÃ  **GPT Pre-trained**

---

## âš™ï¸ CÃ¡ch cháº¡y dá»± Ã¡n

### 1ï¸âƒ£ Clone repo
```bash
git clone https://github.com/quocduy1234231/Vietnamese-Text-Summarization-Translation.git
