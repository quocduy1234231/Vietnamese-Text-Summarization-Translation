{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"accelerator":"GPU","colab":{"include_colab_link":true,"name":"transformer.ipynb","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11306145,"sourceType":"datasetVersion","datasetId":7070740},{"sourceId":11597755,"sourceType":"datasetVersion","datasetId":7273187}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":15993.932798,"end_time":"2025-04-28T08:42:29.704888","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-28T04:15:55.772090","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"fff059cd","cell_type":"code","source":"! pip -q install torchtext==0.6.0\n! pip -q install pyvi \n\nimport nltk\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:40:08.302169Z","iopub.execute_input":"2025-04-29T07:40:08.302916Z","iopub.status.idle":"2025-04-29T07:41:18.838223Z","shell.execute_reply.started":"2025-04-29T07:40:08.302889Z","shell.execute_reply":"2025-04-29T07:41:18.837398Z"},"id":"RVOKeezWPsSs","papermill":{"duration":76.241017,"end_time":"2025-04-28T04:17:15.994580","exception":false,"start_time":"2025-04-28T04:15:59.753563","status":"completed"},"tags":[],"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"id":"dd28eacb","cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\nimport os\nimport math","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:21.047571Z","iopub.execute_input":"2025-04-29T07:41:21.048201Z","iopub.status.idle":"2025-04-29T07:41:21.052125Z","shell.execute_reply.started":"2025-04-29T07:41:21.048173Z","shell.execute_reply":"2025-04-29T07:41:21.051563Z"},"id":"8gvN64qvNQIS","papermill":{"duration":3.219339,"end_time":"2025-04-28T04:17:19.235630","exception":false,"start_time":"2025-04-28T04:17:16.016291","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":6},{"id":"2818175c","cell_type":"markdown","source":"# Kiến trúc mô hình","metadata":{"papermill":{"duration":0.020939,"end_time":"2025-04-28T04:17:19.280377","exception":false,"start_time":"2025-04-28T04:17:19.259438","status":"completed"},"tags":[]}},{"id":"c1986c40","cell_type":"code","source":"class Embedder(nn.Module):\n    def __init__(self, vocab_size, d_model):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.d_model = d_model\n        \n        self.embed = nn.Embedding(vocab_size, d_model)\n        \n    def forward(self, x):\n        return self.embed(x)\n        ","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:24.424471Z","iopub.execute_input":"2025-04-29T07:41:24.424722Z","iopub.status.idle":"2025-04-29T07:41:24.429089Z","shell.execute_reply.started":"2025-04-29T07:41:24.424704Z","shell.execute_reply":"2025-04-29T07:41:24.428311Z"},"id":"X9da_ZuSNQIW","papermill":{"duration":0.027454,"end_time":"2025-04-28T04:17:19.335591","exception":false,"start_time":"2025-04-28T04:17:19.308137","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"id":"356f772d","cell_type":"code","source":"class PositionalEncoder(nn.Module):\n    def __init__(self, d_model, max_seq_length=200, dropout=0.1):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.dropout = nn.Dropout(dropout)\n        \n        pe = torch.zeros(max_seq_length, d_model)\n        \n        # Bảng pe mình vẽ ở trên \n        for pos in range(max_seq_length):\n            for i in range(0, d_model, 2):\n                pe[pos, i] = math.sin(pos/(10000**(2*i/d_model)))\n                pe[pos, i+1] = math.cos(pos/(10000**((2*i+1)/d_model)))\n        pe = pe.unsqueeze(0)        \n        self.register_buffer('pe', pe)\n    \n    def forward(self, x):\n        \n        x = x*math.sqrt(self.d_model)\n        seq_length = x.size(1)\n        \n        pe = Variable(self.pe[:, :seq_length], requires_grad=False)\n        \n        if x.is_cuda:\n            pe.cuda()\n        # cộng embedding vector với pe \n        x = x + pe\n        x = self.dropout(x)\n        \n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:25.543138Z","iopub.execute_input":"2025-04-29T07:41:25.543952Z","iopub.status.idle":"2025-04-29T07:41:25.550377Z","shell.execute_reply.started":"2025-04-29T07:41:25.543921Z","shell.execute_reply":"2025-04-29T07:41:25.549610Z"},"id":"rP64KizDNQIa","papermill":{"duration":0.028798,"end_time":"2025-04-28T04:17:19.392325","exception":false,"start_time":"2025-04-28T04:17:19.363527","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"fd2dc6e1","cell_type":"code","source":"def attention(q, k, v, mask=None, dropout=None):\n    \"\"\"\n    q: batch_size x head x seq_length x d_model\n    k: batch_size x head x seq_length x d_model\n    v: batch_size x head x seq_length x d_model\n    mask: batch_size x 1 x 1 x seq_length\n    output: batch_size x head x seq_length x d_model\n    \"\"\"\n\n    # attention score được tính bằng cách nhân q với k\n    d_k = q.size(-1)\n    scores = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(d_k)\n    \n    if mask is not None:\n        mask = mask.unsqueeze(1)\n        scores = scores.masked_fill(mask==0, -1e9)\n    # xong rồi thì chuẩn hóa bằng softmax\n    scores = F.softmax(scores, dim=-1)\n    \n    if dropout is not None:\n        scores = dropout(scores)\n    \n    output = torch.matmul(scores, v)\n    return output, scores\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:26.956406Z","iopub.execute_input":"2025-04-29T07:41:26.956953Z","iopub.status.idle":"2025-04-29T07:41:26.961876Z","shell.execute_reply.started":"2025-04-29T07:41:26.956930Z","shell.execute_reply":"2025-04-29T07:41:26.961037Z"},"id":"2nJMcGuUNQId","papermill":{"duration":0.034616,"end_time":"2025-04-28T04:17:19.447629","exception":false,"start_time":"2025-04-28T04:17:19.413013","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"e5295765","cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, heads, d_model, dropout=0.1):\n        super().__init__()\n        assert d_model % heads == 0\n        \n        self.d_model = d_model\n        self.d_k = d_model//heads\n        self.h = heads\n        self.attn = None\n\n        # tạo ra 3 ma trận trọng số là q_linear, k_linear, v_linear như hình trên\n        self.q_linear = nn.Linear(d_model, d_model)\n        self.k_linear = nn.Linear(d_model, d_model)\n        self.v_linear = nn.Linear(d_model, d_model)\n        \n        self.dropout = nn.Dropout(dropout)\n        self.out = nn.Linear(d_model, d_model)\n    \n    def forward(self, q, k, v, mask=None):\n        \"\"\"\n        q: batch_size x seq_length x d_model\n        k: batch_size x seq_length x d_model\n        v: batch_size x seq_length x d_model\n        mask: batch_size x 1 x seq_length\n        output: batch_size x seq_length x d_model\n        \"\"\"\n        bs = q.size(0)\n        # nhân ma trận trọng số q_linear, k_linear, v_linear với dữ liệu đầu vào q, k, v \n        # ở bước encode các bạn lưu ý rằng q, k, v chỉ là một (xem hình trên)\n        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n        \n        q = q.transpose(1, 2)\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n        \n        # tính attention score\n        scores, self.attn = attention(q, k, v, mask, self.dropout)\n        \n        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n        \n        output = self.out(concat)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:29.372136Z","iopub.execute_input":"2025-04-29T07:41:29.372796Z","iopub.status.idle":"2025-04-29T07:41:29.379724Z","shell.execute_reply.started":"2025-04-29T07:41:29.372769Z","shell.execute_reply":"2025-04-29T07:41:29.378936Z"},"id":"ANQ4C3EENQIh","papermill":{"duration":0.029457,"end_time":"2025-04-28T04:17:19.512582","exception":false,"start_time":"2025-04-28T04:17:19.483125","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"20747922","cell_type":"code","source":"class Norm(nn.Module):\n    def __init__(self, d_model, eps = 1e-6):\n        super().__init__()\n    \n        self.size = d_model\n        \n        # create two learnable parameters to calibrate normalisation\n        self.alpha = nn.Parameter(torch.ones(self.size))\n        self.bias = nn.Parameter(torch.zeros(self.size))\n        \n        self.eps = eps\n    \n    def forward(self, x):\n        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n        return norm","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:30.622069Z","iopub.execute_input":"2025-04-29T07:41:30.622359Z","iopub.status.idle":"2025-04-29T07:41:30.627217Z","shell.execute_reply.started":"2025-04-29T07:41:30.622339Z","shell.execute_reply":"2025-04-29T07:41:30.626661Z"},"id":"n6-_9Hq-NQIk","papermill":{"duration":0.089374,"end_time":"2025-04-28T04:17:19.629457","exception":false,"start_time":"2025-04-28T04:17:19.540083","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"7e5db42d","cell_type":"code","source":"class FeedForward(nn.Module):\n    \"\"\" Trong kiến trúc của chúng ta có tầng linear \n    \"\"\"\n    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n        super().__init__() \n    \n        # We set d_ff as a default to 2048\n        self.linear_1 = nn.Linear(d_model, d_ff)\n        self.dropout = nn.Dropout(dropout)\n        self.linear_2 = nn.Linear(d_ff, d_model)\n    \n    def forward(self, x):\n        x = self.dropout(F.relu(self.linear_1(x)))\n        x = self.linear_2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:32.158717Z","iopub.execute_input":"2025-04-29T07:41:32.159392Z","iopub.status.idle":"2025-04-29T07:41:32.163973Z","shell.execute_reply.started":"2025-04-29T07:41:32.159365Z","shell.execute_reply":"2025-04-29T07:41:32.163230Z"},"id":"H1ndbdMXNQIn","papermill":{"duration":0.027125,"end_time":"2025-04-28T04:17:19.688055","exception":false,"start_time":"2025-04-28T04:17:19.660930","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"247e25e5","cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self, d_model, heads, dropout=0.1):\n        super().__init__()\n        self.norm_1 = Norm(d_model)\n        self.norm_2 = Norm(d_model)\n        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n        self.ff = FeedForward(d_model, dropout=dropout)\n        self.dropout_1 = nn.Dropout(dropout)\n        self.dropout_2 = nn.Dropout(dropout)\n        \n    def forward(self, x, mask):\n        \"\"\"\n        x: batch_size x seq_length x d_model\n        mask: batch_size x 1 x seq_length\n        output: batch_size x seq_length x d_model\n        \"\"\"\n        \n        \n        x2 = self.norm_1(x)\n        # tính attention value, các bạn để ý q, k, v là giống nhau        \n        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n        x2 = self.norm_2(x)\n        x = x + self.dropout_2(self.ff(x2))\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:33.482477Z","iopub.execute_input":"2025-04-29T07:41:33.483017Z","iopub.status.idle":"2025-04-29T07:41:33.488283Z","shell.execute_reply.started":"2025-04-29T07:41:33.482993Z","shell.execute_reply":"2025-04-29T07:41:33.487449Z"},"id":"-Wwo91xDNQIq","papermill":{"duration":0.026944,"end_time":"2025-04-28T04:17:19.744338","exception":false,"start_time":"2025-04-28T04:17:19.717394","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"b4ff9bbe","cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, d_model, heads, dropout=0.1):\n        super().__init__()\n        self.norm_1 = Norm(d_model)\n        self.norm_2 = Norm(d_model)\n        self.norm_3 = Norm(d_model)\n        \n        self.dropout_1 = nn.Dropout(dropout)\n        self.dropout_2 = nn.Dropout(dropout)\n        self.dropout_3 = nn.Dropout(dropout)\n        \n        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n        self.ff = FeedForward(d_model, dropout=dropout)\n\n    def forward(self, x, e_outputs, src_mask, trg_mask):\n        \"\"\"\n        x: batch_size x seq_length x d_model\n        e_outputs: batch_size x seq_length x d_model\n        src_mask: batch_size x 1 x seq_length\n        trg_mask: batch_size x 1 x seq_length\n        \"\"\"\n        # Các bạn xem hình trên, kiến trúc mình vẽ với code ở chỗ này tương đương nhau.\n        x2 = self.norm_1(x)\n        # multihead attention thứ nhất, chú ý các từ ở target \n        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n        x2 = self.norm_2(x)\n        # masked mulithead attention thứ 2. k, v là giá trị output của mô hình encoder\n        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n        x2 = self.norm_3(x)\n        x = x + self.dropout_3(self.ff(x2))\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:34.621614Z","iopub.execute_input":"2025-04-29T07:41:34.622190Z","iopub.status.idle":"2025-04-29T07:41:34.628266Z","shell.execute_reply.started":"2025-04-29T07:41:34.622170Z","shell.execute_reply":"2025-04-29T07:41:34.627592Z"},"id":"6mDt2NPeNQIu","papermill":{"duration":0.027894,"end_time":"2025-04-28T04:17:19.793231","exception":false,"start_time":"2025-04-28T04:17:19.765337","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"id":"31655df9","cell_type":"markdown","source":"Cài đặt Encoder\nbao gồm N encoder layer","metadata":{"id":"lk1c6NkYIeG8","papermill":{"duration":0.020638,"end_time":"2025-04-28T04:17:19.834553","exception":false,"start_time":"2025-04-28T04:17:19.813915","status":"completed"},"tags":[]}},{"id":"170bb61a","cell_type":"code","source":"import copy\n\ndef get_clones(module, N):\n    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n\nclass Encoder(nn.Module):\n    \"\"\"Một encoder có nhiều encoder layer nhé !!!\n    \"\"\"\n    def __init__(self, vocab_size, d_model, N, heads, dropout):\n        super().__init__()\n        self.N = N\n        self.embed = Embedder(vocab_size, d_model)\n        self.pe = PositionalEncoder(d_model, dropout=dropout)\n        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n        self.norm = Norm(d_model)\n        \n    def forward(self, src, mask):\n        \"\"\"\n        src: batch_size x seq_length\n        mask: batch_size x 1 x seq_length\n        output: batch_size x seq_length x d_model\n        \"\"\"\n        x = self.embed(src)\n        x = self.pe(x)\n        for i in range(self.N):\n            x = self.layers[i](x, mask)\n        return self.norm(x)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:37.451055Z","iopub.execute_input":"2025-04-29T07:41:37.451808Z","iopub.status.idle":"2025-04-29T07:41:37.457762Z","shell.execute_reply.started":"2025-04-29T07:41:37.451776Z","shell.execute_reply":"2025-04-29T07:41:37.456862Z"},"id":"ZcU8nyvzNQIx","papermill":{"duration":0.030289,"end_time":"2025-04-28T04:17:19.885563","exception":false,"start_time":"2025-04-28T04:17:19.855274","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"id":"8e894bf2","cell_type":"markdown","source":"Cài đặt Decoder\nbao gồm N decoder layers","metadata":{"id":"Qip-E_TAIpmJ","papermill":{"duration":0.02046,"end_time":"2025-04-28T04:17:19.936215","exception":false,"start_time":"2025-04-28T04:17:19.915755","status":"completed"},"tags":[]}},{"id":"c2061fa7","cell_type":"code","source":"class Decoder(nn.Module):\n    \"\"\"Một decoder có nhiều decoder layer nhé !!!\n    \"\"\"\n    def __init__(self, vocab_size, d_model, N, heads, dropout):\n        super().__init__()\n        self.N = N\n        self.embed = Embedder(vocab_size, d_model)\n        self.pe = PositionalEncoder(d_model, dropout=dropout)\n        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n        self.norm = Norm(d_model)\n    def forward(self, trg, e_outputs, src_mask, trg_mask):\n        \"\"\"\n        trg: batch_size x seq_length\n        e_outputs: batch_size x seq_length x d_model\n        src_mask: batch_size x 1 x seq_length\n        trg_mask: batch_size x 1 x seq_length\n        output: batch_size x seq_length x d_model\n        \"\"\"\n        x = self.embed(trg)\n        x = self.pe(x)\n        for i in range(self.N):\n            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n        return self.norm(x)\n    ","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:40.340842Z","iopub.execute_input":"2025-04-29T07:41:40.341372Z","iopub.status.idle":"2025-04-29T07:41:40.346605Z","shell.execute_reply.started":"2025-04-29T07:41:40.341349Z","shell.execute_reply":"2025-04-29T07:41:40.345842Z"},"id":"5lBRYMg_NQI0","papermill":{"duration":0.027505,"end_time":"2025-04-28T04:17:19.984420","exception":false,"start_time":"2025-04-28T04:17:19.956915","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"60fab9db","cell_type":"markdown","source":"Cài đặt Transformer \nbao gồm encoder và decoder","metadata":{"id":"gDVQGAaMI5UU","papermill":{"duration":0.020652,"end_time":"2025-04-28T04:17:20.026257","exception":false,"start_time":"2025-04-28T04:17:20.005605","status":"completed"},"tags":[]}},{"id":"989249cf","cell_type":"code","source":"class Transformer(nn.Module):\n    \"\"\" Cuối cùng ghép chúng lại với nhau để được mô hình transformer hoàn chỉnh\n    \"\"\"\n    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n        super().__init__()\n        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n        self.out = nn.Linear(d_model, trg_vocab)\n    def forward(self, src, trg, src_mask, trg_mask):\n        \"\"\"\n        src: batch_size x seq_length\n        trg: batch_size x seq_length\n        src_mask: batch_size x 1 x seq_length\n        trg_mask batch_size x 1 x seq_length\n        output: batch_size x seq_length x vocab_size\n        \"\"\"\n        e_outputs = self.encoder(src, src_mask)\n        \n        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n        output = self.out(d_output)\n        return output\n        ","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:42.884210Z","iopub.execute_input":"2025-04-29T07:41:42.884544Z","iopub.status.idle":"2025-04-29T07:41:42.889935Z","shell.execute_reply.started":"2025-04-29T07:41:42.884516Z","shell.execute_reply":"2025-04-29T07:41:42.889308Z"},"id":"DpxSCRILNQI3","papermill":{"duration":0.026971,"end_time":"2025-04-28T04:17:20.073862","exception":false,"start_time":"2025-04-28T04:17:20.046891","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"13cc09d6","cell_type":"markdown","source":"Load dữ liệu\n","metadata":{"papermill":{"duration":0.020642,"end_time":"2025-04-28T04:17:20.115174","exception":false,"start_time":"2025-04-28T04:17:20.094532","status":"completed"},"tags":[]}},{"id":"c5be0856","cell_type":"markdown","source":"Chúng ta sử dụng torchtext để load dữ liệu, giúp giảm thời gian và hiệu quả ","metadata":{"id":"PVj-ECLzHLxf","papermill":{"duration":0.021129,"end_time":"2025-04-28T04:17:20.157667","exception":false,"start_time":"2025-04-28T04:17:20.136538","status":"completed"},"tags":[]}},{"id":"1cd3f327","cell_type":"code","source":"from torchtext import data\n\nclass MyIterator(data.Iterator):\n    def create_batches(self):\n        if self.train:\n            def pool(d, random_shuffler):\n                for p in data.batch(d, self.batch_size * 100):\n                    p_batch = data.batch(\n                        sorted(p, key=self.sort_key),\n                        self.batch_size, self.batch_size_fn)\n                    for b in random_shuffler(list(p_batch)):\n                        yield b\n            self.batches = pool(self.data(), self.random_shuffler)\n            \n        else:\n            self.batches = []\n            for b in data.batch(self.data(), self.batch_size,\n                                          self.batch_size_fn):\n                self.batches.append(sorted(b, key=self.sort_key))\n\nglobal max_src_in_batch, max_tgt_in_batch\n\ndef batch_size_fn(new, count, sofar):\n    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n    global max_src_in_batch, max_tgt_in_batch\n    if count == 1:\n        max_src_in_batch = 0\n        max_tgt_in_batch = 0\n    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n    src_elements = count * max_src_in_batch\n    tgt_elements = count * max_tgt_in_batch\n    return max(src_elements, tgt_elements)\n    ","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:46.256386Z","iopub.execute_input":"2025-04-29T07:41:46.257127Z","iopub.status.idle":"2025-04-29T07:41:46.385731Z","shell.execute_reply.started":"2025-04-29T07:41:46.257100Z","shell.execute_reply":"2025-04-29T07:41:46.385025Z"},"id":"M5tvzW9jNQI6","papermill":{"duration":0.13975,"end_time":"2025-04-28T04:17:20.317956","exception":false,"start_time":"2025-04-28T04:17:20.178206","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"ea246084","cell_type":"code","source":"def nopeak_mask(size, device):\n    \"\"\"Tạo mask được sử dụng trong decoder để lúc dự đoán trong quá trình huấn luyện\n     mô hình không nhìn thấy được các từ ở tương lai\n    \"\"\"\n    np_mask = np.triu(np.ones((1, size, size)),\n    k=1).astype('uint8')\n    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n    np_mask = np_mask.to(device)\n    \n    return np_mask\n\ndef create_masks(src, trg, src_pad, trg_pad, device):\n    \"\"\" Tạo mask cho encoder, \n    để mô hình không bỏ qua thông tin của các kí tự PAD do chúng ta thêm vào \n    \"\"\"\n    src_mask = (src != src_pad).unsqueeze(-2)\n\n    if trg is not None:\n        trg_mask = (trg != trg_pad).unsqueeze(-2)\n        size = trg.size(1) # get seq_len for matrix\n        np_mask = nopeak_mask(size, device)\n        if trg.is_cuda:\n            np_mask.cuda()\n        trg_mask = trg_mask & np_mask\n        \n    else:\n        trg_mask = None\n    return src_mask, trg_mask\n    ","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:47.753507Z","iopub.execute_input":"2025-04-29T07:41:47.754187Z","iopub.status.idle":"2025-04-29T07:41:47.759485Z","shell.execute_reply.started":"2025-04-29T07:41:47.754163Z","shell.execute_reply":"2025-04-29T07:41:47.758761Z"},"id":"NkBjLH96NQI8","papermill":{"duration":0.027273,"end_time":"2025-04-28T04:17:20.366286","exception":false,"start_time":"2025-04-28T04:17:20.339013","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":19},{"id":"8d312fe2","cell_type":"code","source":"import nltk\nimport re\nfrom nltk.tokenize import word_tokenize\n\nclass tokenize(object):\n    \n    def __init__(self, lang=None):\n        pass  \n            \n    def tokenizer(self, sentence):\n        sentence = re.sub(\n            r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n        sentence = re.sub(r\"\\,+\", \",\", sentence)\n        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n        sentence = sentence.lower()\n        return word_tokenize(sentence)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:49.590173Z","iopub.execute_input":"2025-04-29T07:41:49.590850Z","iopub.status.idle":"2025-04-29T07:41:49.595856Z","shell.execute_reply.started":"2025-04-29T07:41:49.590822Z","shell.execute_reply":"2025-04-29T07:41:49.595036Z"},"id":"4Uee4YaQNQI_","papermill":{"duration":0.026691,"end_time":"2025-04-28T04:17:20.413781","exception":false,"start_time":"2025-04-28T04:17:20.387090","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":20},{"id":"4bbe2cd0","cell_type":"markdown","source":"Data loader\nSử dụng torchtext để load dữ liệu nhanh chóng","metadata":{"id":"x2jMF9lzQ4a8","papermill":{"duration":0.020769,"end_time":"2025-04-28T04:17:20.456081","exception":false,"start_time":"2025-04-28T04:17:20.435312","status":"completed"},"tags":[]}},{"id":"823ab73d","cell_type":"code","source":"import os\nimport dill as pickle\nimport pandas as pd\n\ndef read_data(src_file, trg_file):\n    src_data = open(src_file).read().strip().split('\\n')\n\n    trg_data = open(trg_file).read().strip().split('\\n')\n \n    return src_data, trg_data\n\ndef create_fields(src_lang, trg_lang):\n    t_src = tokenize(src_lang)\n    t_trg = tokenize(trg_lang)\n\n    TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n    SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n        \n    return SRC, TRG\n\ndef create_dataset(src_data, trg_data, max_strlen, batchsize, device, SRC, TRG, istrain=True):\n\n    print(\"Creating dataset and Iterator... \")\n\n    raw_data = {'src' : [line for line in src_data], 'trg': [line for line in trg_data]}\n    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n    \n    mask = (df['src'].str.count(' ') < max_strlen) & (df['trg'].str.count(' ') < max_strlen)\n    df = df.loc[mask]\n\n    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n    \n    data_fields = [('src', SRC), ('trg', TRG)]\n    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n\n    train_iter = MyIterator(train, batch_size=batchsize, device=device,\n                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n                        batch_size_fn=batch_size_fn, train=istrain, shuffle=True)\n    \n    os.remove('translate_transformer_temp.csv')\n    \n    if istrain:\n        SRC.build_vocab(train)\n        TRG.build_vocab(train)\n\n    return train_iter\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:52.240140Z","iopub.execute_input":"2025-04-29T07:41:52.240655Z","iopub.status.idle":"2025-04-29T07:41:52.639055Z","shell.execute_reply.started":"2025-04-29T07:41:52.240631Z","shell.execute_reply":"2025-04-29T07:41:52.638517Z"},"id":"_uVO0yr_NQJC","papermill":{"duration":1.513411,"end_time":"2025-04-28T04:17:21.990033","exception":false,"start_time":"2025-04-28T04:17:20.476622","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":21},{"id":"6646d325","cell_type":"code","source":"def step(model, optimizer, batch, criterion):\n    \"\"\"\n    Một lần cập nhật mô hình\n    \"\"\"\n    model.train()\n\n    # Chuyển dữ liệu vào device (CUDA)\n    src = batch.src.transpose(0, 1).cuda()\n    trg = batch.trg.transpose(0, 1).cuda()\n    trg_input = trg[:, :-1]\n    \n    # Tạo mask cho source và target\n    src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n    \n    # Dự đoán từ mô hình\n    preds = model(src, trg_input, src_mask, trg_mask)\n    \n    # Định dạng lại target\n    ys = trg[:, 1:].contiguous().view(-1)\n\n    # Zero gradients từ optimizer\n    optimizer.zero_grad()\n    \n    # Tính toán loss\n    loss = criterion(preds.view(-1, preds.size(-1)), ys)\n    \n    # Backpropagate lỗi\n    loss.backward()\n    \n    # Cập nhật các tham số của mô hình\n    optimizer.step()\n\n\n    loss = loss.item()\n    \n    return loss\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:54.087209Z","iopub.execute_input":"2025-04-29T07:41:54.087740Z","iopub.status.idle":"2025-04-29T07:41:54.093715Z","shell.execute_reply.started":"2025-04-29T07:41:54.087715Z","shell.execute_reply":"2025-04-29T07:41:54.092920Z"},"id":"l4POJRxdNQJF","papermill":{"duration":0.027548,"end_time":"2025-04-28T04:17:22.039538","exception":false,"start_time":"2025-04-28T04:17:22.011990","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":22},{"id":"8df7176c","cell_type":"code","source":"def validiate(model, valid_iter, criterion):\n    \"\"\" Tính loss trên tập validation\n    \"\"\"\n    model.eval()\n    \n    with torch.no_grad():\n        total_loss = []\n        for batch in valid_iter:\n            src = batch.src.transpose(0,1).cuda()\n            trg = batch.trg.transpose(0,1).cuda()\n            trg_input = trg[:, :-1]\n            src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n            preds = model(src, trg_input, src_mask, trg_mask)\n\n            ys = trg[:, 1:].contiguous().view(-1)\n            \n            loss = criterion(preds.view(-1, preds.size(-1)), ys)\n            \n            loss = loss.item()\n            \n            total_loss.append(loss)\n        \n    avg_loss = np.mean(total_loss)\n    \n    return avg_loss\n    ","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:55.560720Z","iopub.execute_input":"2025-04-29T07:41:55.560985Z","iopub.status.idle":"2025-04-29T07:41:55.566686Z","shell.execute_reply.started":"2025-04-29T07:41:55.560966Z","shell.execute_reply":"2025-04-29T07:41:55.565903Z"},"id":"c5sPA-k_NQJI","papermill":{"duration":0.027629,"end_time":"2025-04-28T04:17:22.088106","exception":false,"start_time":"2025-04-28T04:17:22.060477","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":23},{"id":"b6fe84d1","cell_type":"markdown","source":"# Tạo các file data","metadata":{"papermill":{"duration":0.020505,"end_time":"2025-04-28T04:17:22.129454","exception":false,"start_time":"2025-04-28T04:17:22.108949","status":"completed"},"tags":[]}},{"id":"efa1bec0","cell_type":"code","source":"%ls /kaggle/input/","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:41:57.312591Z","iopub.execute_input":"2025-04-29T07:41:57.312869Z","iopub.status.idle":"2025-04-29T07:41:57.461036Z","shell.execute_reply.started":"2025-04-29T07:41:57.312849Z","shell.execute_reply":"2025-04-29T07:41:57.460080Z"},"papermill":{"duration":0.161676,"end_time":"2025-04-28T04:17:22.312039","exception":false,"start_time":"2025-04-28T04:17:22.150363","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mmt-dataset\u001b[0m/  \u001b[01;34mweight-mt-scatch-trans\u001b[0m/\n","output_type":"stream"}],"execution_count":24},{"id":"7d3fbf9d","cell_type":"code","source":"import os\n\n# Đường dẫn input\nen_path = '/kaggle/input/mt-dataset/en_sents_dataset.txt'\nvi_path = '/kaggle/input/mt-dataset/vi_sents_dataset.txt'\n\n# Tạo thư mục output\nos.makedirs('./data', exist_ok=True)\n\n# Số câu cho tập valid\nvalid_size = 500\n\n# Đọc dữ liệu\nwith open(en_path, 'r', encoding='utf-8') as f:\n    en_lines = f.readlines()\nwith open(vi_path, 'r', encoding='utf-8') as f:\n    vi_lines = f.readlines()\n\n# Kiểm tra số lượng câu khớp nhau\nassert len(en_lines) == len(vi_lines), \"Hai file phải có cùng số lượng câu!\"\n\n# Ghi file train\nwith open('./data/train.en', 'w', encoding='utf-8') as f:\n    f.writelines(en_lines[valid_size:])\nwith open('./data/train.vi', 'w', encoding='utf-8') as f:\n    f.writelines(vi_lines[valid_size:])\n\n# Ghi file valid\nwith open('./data/valid.en', 'w', encoding='utf-8') as f:\n    f.writelines(en_lines[:valid_size])\nwith open('./data/valid.vi', 'w', encoding='utf-8') as f:\n    f.writelines(vi_lines[:valid_size])\n\nprint(f\"\"\"\nĐã tạo thành công:\n- ./data/train.en ({len(en_lines)-valid_size} câu)\n- ./data/train.vi ({len(vi_lines)-valid_size} câu)\n- ./data/valid.en ({valid_size} câu)\n- ./data/valid.vi ({valid_size} câu)\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:42:15.983995Z","iopub.execute_input":"2025-04-29T07:42:15.984523Z","iopub.status.idle":"2025-04-29T07:42:18.717516Z","shell.execute_reply.started":"2025-04-29T07:42:15.984500Z","shell.execute_reply":"2025-04-29T07:42:18.716664Z"},"papermill":{"duration":2.743175,"end_time":"2025-04-28T04:17:25.077792","exception":false,"start_time":"2025-04-28T04:17:22.334617","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\nĐã tạo thành công:\n- ./data/train.en (745890 câu)\n- ./data/train.vi (745890 câu)\n- ./data/valid.en (500 câu)\n- ./data/valid.vi (500 câu)\n\n","output_type":"stream"}],"execution_count":26},{"id":"f87d8c86","cell_type":"code","source":"opt = {\n    'train_src_data':'./data/train.en',\n    'train_trg_data':'./data/train.vi',\n    'valid_src_data':'./data/valid.en',\n    'valid_trg_data':'./data/valid.vi',\n    'src_lang':'en',\n    'trg_lang':'vi',\n    'max_strlen':160,\n    'batchsize':1500,\n    'device':'cuda',\n    'd_model': 512,\n    'n_layers': 6,\n    'heads': 8,\n    'dropout': 0.1,\n    'lr':0.0001,\n    'epochs':5,\n    'printevery': 6000,\n    'k':5,\n}","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:42:22.065931Z","iopub.execute_input":"2025-04-29T07:42:22.066611Z","iopub.status.idle":"2025-04-29T07:42:22.070714Z","shell.execute_reply.started":"2025-04-29T07:42:22.066588Z","shell.execute_reply":"2025-04-29T07:42:22.070026Z"},"id":"Nhgu-SPTNQJL","papermill":{"duration":0.026932,"end_time":"2025-04-28T04:17:25.126653","exception":false,"start_time":"2025-04-28T04:17:25.099721","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":27},{"id":"6bd5dd1c","cell_type":"code","source":"train_src_data, train_trg_data = read_data(opt['train_src_data'], opt['train_trg_data'])\nvalid_src_data, valid_trg_data = read_data(opt['valid_src_data'], opt['valid_trg_data'])\n\nSRC, TRG = create_fields(opt['src_lang'], opt['trg_lang'])\ntrain_iter = create_dataset(train_src_data, train_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=True)\nvalid_iter = create_dataset(valid_src_data, valid_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=False)","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:42:23.773617Z","iopub.execute_input":"2025-04-29T07:42:23.774146Z","iopub.status.idle":"2025-04-29T07:45:43.956571Z","shell.execute_reply.started":"2025-04-29T07:42:23.774124Z","shell.execute_reply":"2025-04-29T07:45:43.955787Z"},"id":"IBotIB8pNQJU","outputId":"12e472e9-08b7-451b-f89f-15d1c6df2e0b","papermill":{"duration":199.807244,"end_time":"2025-04-28T04:20:44.956178","exception":false,"start_time":"2025-04-28T04:17:25.148934","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Creating dataset and Iterator... \nCreating dataset and Iterator... \n","output_type":"stream"}],"execution_count":28},{"id":"f93e1cf4","cell_type":"code","source":"src_pad = SRC.vocab.stoi['<pad>']\ntrg_pad = TRG.vocab.stoi['<pad>']","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:45:51.870785Z","iopub.execute_input":"2025-04-29T07:45:51.871393Z","iopub.status.idle":"2025-04-29T07:45:51.874613Z","shell.execute_reply.started":"2025-04-29T07:45:51.871371Z","shell.execute_reply":"2025-04-29T07:45:51.873883Z"},"id":"Gnw9xrJeNQJX","papermill":{"duration":0.027204,"end_time":"2025-04-28T04:20:45.004770","exception":false,"start_time":"2025-04-28T04:20:44.977566","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":30},{"id":"7aec9ee4","cell_type":"code","source":"model = Transformer(len(SRC.vocab), len(TRG.vocab), opt['d_model'], opt['n_layers'], opt['heads'], opt['dropout'])\nmodel = model.to(opt['device'])","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:45:53.608363Z","iopub.execute_input":"2025-04-29T07:45:53.609059Z","iopub.status.idle":"2025-04-29T07:45:58.042525Z","shell.execute_reply.started":"2025-04-29T07:45:53.609035Z","shell.execute_reply":"2025-04-29T07:45:58.041931Z"},"id":"5RccNL8VNQJd","papermill":{"duration":4.501907,"end_time":"2025-04-28T04:20:49.527795","exception":false,"start_time":"2025-04-28T04:20:45.025888","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":31},{"id":"1c3787fa-f43f-485a-92e2-c7a1d458d344","cell_type":"markdown","source":"# Training model","metadata":{}},{"id":"4c1ce0f3","cell_type":"code","source":"# Khởi tạo optimizer\noptimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09)\n\n# Định nghĩa Loss function\ncriterion = nn.CrossEntropyLoss(ignore_index=trg_pad)","metadata":{"execution":{"iopub.execute_input":"2025-04-28T04:20:49.571944Z","iopub.status.busy":"2025-04-28T04:20:49.571658Z","iopub.status.idle":"2025-04-28T04:20:53.580214Z","shell.execute_reply":"2025-04-28T04:20:53.579614Z"},"id":"12debLGiNQJg","papermill":{"duration":4.031757,"end_time":"2025-04-28T04:20:53.581582","exception":false,"start_time":"2025-04-28T04:20:49.549825","status":"completed"},"tags":[]},"outputs":[],"execution_count":26},{"id":"49834ef7","cell_type":"code","source":"import torch\n\n# Khởi tạo biến để lưu history\ntrain_loss_history = []\nvalid_loss_history = []\n\n# Hàm lưu mô hình\ndef save_model(model, epoch, path=\"model.pth\"):\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': total_loss,\n    }, path)\n    print(f\"Model saved at epoch {epoch+1}!\")\n\nbest_loss = float('inf')\nfor epoch in range(opt['epochs']):\n    print(f\"\"\"*** TRAINING EPOCH {epoch + 1} ***\"\"\")\n    total_loss = 0\n    \n    model.train()  # Đảm bảo mô hình ở chế độ huấn luyện\n    for i, batch in enumerate(train_iter): \n        loss = step(model, optimizer, batch, criterion)\n        total_loss += loss\n        \n        # In ra kết quả nếu đến thời điểm in\n        if (i + 1) % opt['printevery'] == 0:\n            avg_loss = total_loss / opt['printevery']\n            print(f' \\tIter: {i + 1} - Train loss: {avg_loss}')\n            total_loss = 0\n\n    # Lưu giá trị train loss cho epoch\n    avg_train_loss = total_loss / (i + 1)  \n    train_loss_history.append(avg_train_loss)\n\n    # Đánh giá validation loss\n    model.eval()  # Đảm bảo mô hình ở chế độ đánh giá\n    valid_loss = validiate(model, valid_iter, criterion)\n    valid_loss_history.append(valid_loss)\n\n    print(\"\"\"**** VALIDATION ***\"\"\")\n    print(f'Epoch: {epoch+1} - Val loss: {valid_loss}')\n    \n    # Lưu mô hình nếu có sự cải thiện \n    if best_loss > valid_loss:\n        best_loss = valid_loss\n        save_model(model, epoch, path=\"model_mt.pth\")\n","metadata":{"execution":{"iopub.execute_input":"2025-04-28T04:20:53.625864Z","iopub.status.busy":"2025-04-28T04:20:53.625506Z","iopub.status.idle":"2025-04-28T08:42:21.367703Z","shell.execute_reply":"2025-04-28T08:42:21.366746Z"},"id":"JeZqfQPANQJl","outputId":"1ac374a6-7ce3-46da-fe7e-47a8463148ed","papermill":{"duration":15687.765479,"end_time":"2025-04-28T08:42:21.369384","exception":false,"start_time":"2025-04-28T04:20:53.603905","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["*** TRAINING EPOCH 1 ***\n"," \tIter: 6000 - Train loss: 4.138365945140521\n"," \tIter: 12000 - Train loss: 3.569727176487446\n","**** VALIDATION ***\n","Epoch: 1 - Val loss: 1.5856701850891113\n","Model saved at epoch 1!\n","*** TRAINING EPOCH 2 ***\n"," \tIter: 6000 - Train loss: 3.5314211794137953\n"," \tIter: 12000 - Train loss: 3.540176963031292\n","**** VALIDATION ***\n","Epoch: 2 - Val loss: 1.3945751190185547\n","Model saved at epoch 2!\n","*** TRAINING EPOCH 3 ***\n"," \tIter: 6000 - Train loss: 3.436589025378227\n"," \tIter: 12000 - Train loss: 3.335584201713403\n","**** VALIDATION ***\n","Epoch: 3 - Val loss: 1.1621538400650024\n","Model saved at epoch 3!\n","*** TRAINING EPOCH 4 ***\n"," \tIter: 6000 - Train loss: 3.2003503495057424\n"," \tIter: 12000 - Train loss: 3.12177966239055\n","**** VALIDATION ***\n","Epoch: 4 - Val loss: 1.0084938883781434\n","Model saved at epoch 4!\n","*** TRAINING EPOCH 5 ***\n"," \tIter: 6000 - Train loss: 2.956598842302958\n"," \tIter: 12000 - Train loss: 2.897527417322\n","**** VALIDATION ***\n","Epoch: 5 - Val loss: 0.8986941814422608\n","Model saved at epoch 5!\n"]}],"execution_count":27},{"id":"1506556a","cell_type":"markdown","source":"# Thực nghiệm","metadata":{"papermill":{"duration":0.026811,"end_time":"2025-04-28T08:42:21.420014","exception":false,"start_time":"2025-04-28T08:42:21.393203","status":"completed"},"tags":[]}},{"id":"7475c849","cell_type":"code","source":"from nltk.corpus import wordnet\nimport re\n\ndef get_synonym(word, SRC):\n    syns = wordnet.synsets(word)\n    for s in syns:\n        for l in s.lemmas():\n            if l.name() in SRC.vocab.stoi:  # Kiểm tra nếu từ đồng nghĩa có trong vocab\n                return SRC.vocab.stoi[l.name()]\n            \n    return SRC.vocab.stoi['<unk>']  # Trả về <unk> nếu không tìm thấy từ đồng nghĩa nào hợp lệ\n\ndef multiple_replace(dict, text):\n  # Create a regular expression  from the dictionary keys\n  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n\n  # For each match, look-up corresponding value in dictionary\n  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text) \ndef init_vars(src, model, SRC, TRG, device, k, max_len):\n    \"\"\" Tính toán các ma trận cần thiết trong quá trình translation sau khi mô hình học xong\n    \"\"\"\n    init_tok = TRG.vocab.stoi['<sos>']\n    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n\n    # tính sẵn output của encoder \n    e_output = model.encoder(src, src_mask)\n    \n    outputs = torch.LongTensor([[init_tok]])\n    \n    outputs = outputs.to(device)\n    \n    trg_mask = nopeak_mask(1, device)\n    # dự đoán kí tự đầu tiên\n    out = model.out(model.decoder(outputs,\n    e_output, src_mask, trg_mask))\n    out = F.softmax(out, dim=-1)\n    \n    probs, ix = out[:, -1].data.topk(k)\n    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n    \n    outputs = torch.zeros(k, max_len).long()\n    outputs = outputs.to(device)\n    outputs[:, 0] = init_tok\n    outputs[:, 1] = ix[0]\n    \n    e_outputs = torch.zeros(k, e_output.size(-2),e_output.size(-1))\n   \n    e_outputs = e_outputs.to(device)\n    e_outputs[:, :] = e_output[0]\n    \n    return outputs, e_outputs, log_scores\n\ndef k_best_outputs(outputs, out, log_scores, i, k):\n    \n    probs, ix = out[:, -1].data.topk(k)\n    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n    k_probs, k_ix = log_probs.view(-1).topk(k)\n    \n    row = k_ix // k\n    col = k_ix % k\n\n    outputs[:, :i] = outputs[row, :i]\n    outputs[:, i] = ix[row, col]\n\n    log_scores = k_probs.unsqueeze(0)\n    \n    return outputs, log_scores\n\ndef beam_search(src, model, SRC, TRG, device, k, max_len):    \n\n    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, device, k, max_len)\n    eos_tok = TRG.vocab.stoi['<eos>']\n    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n    ind = None\n    for i in range(2, max_len):\n    \n        trg_mask = nopeak_mask(i, device)\n\n        out = model.out(model.decoder(outputs[:,:i],\n        e_outputs, src_mask, trg_mask))\n\n        out = F.softmax(out, dim=-1)\n    \n        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, k)\n        \n        ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).cuda()\n        for vec in ones:\n            i = vec[0]\n            if sentence_lengths[i]==0: # First end symbol has not been found yet\n                sentence_lengths[i] = vec[1] # Position of first end symbol\n\n        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n\n        if num_finished_sentences == k:\n            alpha = 0.7\n            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n            _, ind = torch.max(log_scores * div, 1)\n            ind = ind.data[0]\n            break\n    \n    if ind is None:\n        \n        length = (outputs[0]==eos_tok).nonzero()[0] if len((outputs[0]==eos_tok).nonzero()) > 0 else -1\n        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n    \n    else:\n        length = (outputs[ind]==eos_tok).nonzero()[0]\n        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])\n        \ndef translate_sentence(sentence, model, SRC, TRG, device, k=5, max_len=50):\n    \"\"\"Dịch câu sử dụng beam search (phiên bản cải tiến)\n    \n    Args:\n        sentence: Câu nguồn cần dịch\n        model: Model Transformer đã trained\n        SRC: Field xử lý ngôn ngữ nguồn\n        TRG: Field xử lý ngôn ngữ đích\n        device: 'cuda' hoặc 'cpu'\n        k: Số lượng beams (mặc định 5)\n        max_len: Độ dài tối đa câu dịch\n    \n    Returns:\n        str: Câu đã dịch\n    \"\"\"\n    model.eval()\n    \n    # 1. Tokenize và numericalize (xử lý OOV)\n    tokens = [token.lower() for token in SRC.tokenize(sentence)]\n    indexed = [SRC.vocab.stoi.get(token, SRC.vocab.stoi['<unk>']) for token in tokens]\n    \n    # 2. Tạo tensor đầu vào [1, seq_len]\n    src_tensor = torch.LongTensor([indexed]).to(device)\n    \n    # 3. Beam search\n    translation = beam_search(src_tensor, model, SRC, TRG, device, k, max_len)\n    \n    # 4. Hậu xử lý\n    translation = multiple_replace({\n        ' ?': '?',\n        ' !': '!',\n        ' .': '.',\n        ' ,': ',',\n        ' \\'': '\\''\n    }, translation)\n    \n    return translation","metadata":{"execution":{"iopub.execute_input":"2025-04-28T08:42:21.476483Z","iopub.status.busy":"2025-04-28T08:42:21.475928Z","iopub.status.idle":"2025-04-28T08:42:21.498599Z","shell.execute_reply":"2025-04-28T08:42:21.497896Z"},"papermill":{"duration":0.056374,"end_time":"2025-04-28T08:42:21.499835","exception":false,"start_time":"2025-04-28T08:42:21.443461","status":"completed"},"tags":[]},"outputs":[],"execution_count":28},{"id":"d2d9d894","cell_type":"code","source":"sentences = [\n    \"Can I borrow your book?\",\n    \"I want to learn how solve this problem.\",\n    \"Could you help me find the way to the train station?\",\n    \"Thank you very much for your help.\"\n]\n\n# Testing the translation on each sentence\nfor sentence in sentences:\n    trans_sent = translate_sentence(sentence, model, SRC, TRG, device='cuda', k=5)\n    print(f\"Original: {sentence}\")\n    print(f\"Translated: {trans_sent}\")\n    print(\"-\" * 50)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:50:17.336440Z","iopub.execute_input":"2025-04-29T07:50:17.336736Z","iopub.status.idle":"2025-04-29T07:50:18.253145Z","shell.execute_reply.started":"2025-04-29T07:50:17.336716Z","shell.execute_reply":"2025-04-29T07:50:18.252568Z"},"papermill":{"duration":1.02102,"end_time":"2025-04-28T08:42:22.544137","exception":false,"start_time":"2025-04-28T08:42:21.523117","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Original: Can I borrow your book?\nTranslated: tôi có thể mượn cuốn sách của bạn được không?\n--------------------------------------------------\nOriginal: I want to learn how solve this problem.\nTranslated: tôi muốn học giải quyết vấn đề này như thế nào.\n--------------------------------------------------\nOriginal: Could you help me find the way to the train station?\nTranslated: bạn có thể giúp tôi tìm đường đến ga xe lửa không?\n--------------------------------------------------\nOriginal: Thank you very much for your help.\nTranslated: cảm ơn các bạn rất nhiều vì sự giúp đỡ của bạn.\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":40},{"id":"94942312","cell_type":"markdown","source":"# Evaluate bang BLEU Score","metadata":{"papermill":{"duration":0.023178,"end_time":"2025-04-28T08:42:22.591390","exception":false,"start_time":"2025-04-28T08:42:22.568212","status":"completed"},"tags":[]}},{"id":"4aca7814","cell_type":"code","source":"import torch\n\ncheckpoint = torch.load('/kaggle/input/weight-mt-scatch-trans/model_mt.pth', \n                       map_location='cuda', \n                       weights_only=True)\n\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2025-04-29T07:46:04.820421Z","iopub.execute_input":"2025-04-29T07:46:04.820664Z","iopub.status.idle":"2025-04-29T07:46:09.019511Z","shell.execute_reply.started":"2025-04-29T07:46:04.820648Z","shell.execute_reply":"2025-04-29T07:46:09.018892Z"},"papermill":{"duration":3.866302,"end_time":"2025-04-28T08:42:26.547430","exception":false,"start_time":"2025-04-28T08:42:22.681128","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Transformer(\n  (encoder): Encoder(\n    (embed): Embedder(\n      (embed): Embedding(206392, 512)\n    )\n    (pe): PositionalEncoder(\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): ModuleList(\n      (0-5): 6 x EncoderLayer(\n        (norm_1): Norm()\n        (norm_2): Norm()\n        (attn): MultiHeadAttention(\n          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (ff): FeedForward(\n          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (dropout_1): Dropout(p=0.1, inplace=False)\n        (dropout_2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (norm): Norm()\n  )\n  (decoder): Decoder(\n    (embed): Embedder(\n      (embed): Embedding(170305, 512)\n    )\n    (pe): PositionalEncoder(\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layers): ModuleList(\n      (0-5): 6 x DecoderLayer(\n        (norm_1): Norm()\n        (norm_2): Norm()\n        (norm_3): Norm()\n        (dropout_1): Dropout(p=0.1, inplace=False)\n        (dropout_2): Dropout(p=0.1, inplace=False)\n        (dropout_3): Dropout(p=0.1, inplace=False)\n        (attn_1): MultiHeadAttention(\n          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_2): MultiHeadAttention(\n          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (ff): FeedForward(\n          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n      )\n    )\n    (norm): Norm()\n  )\n  (out): Linear(in_features=512, out_features=170305, bias=True)\n)"},"metadata":{}}],"execution_count":32},{"id":"364a094d-538d-4a0f-aebd-45e6d7a3579d","cell_type":"code","source":"!pip install -q evaluate rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T07:47:25.961384Z","iopub.execute_input":"2025-04-29T07:47:25.962072Z","iopub.status.idle":"2025-04-29T07:47:31.214193Z","shell.execute_reply.started":"2025-04-29T07:47:25.962045Z","shell.execute_reply":"2025-04-29T07:47:31.213321Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":37},{"id":"119e5f73-f337-4425-a188-05d2c86ebb8d","cell_type":"code","source":"def read_data(src_file, trg_file):\n    \"\"\"Đọc dữ liệu từ file nguồn và file đích.\"\"\"\n    try:\n        with open(src_file, 'r', encoding='utf-8') as f_src, \\\n             open(trg_file, 'r', encoding='utf-8') as f_trg:\n            # Đọc từng dòng, loại bỏ khoảng trắng thừa và bỏ qua dòng trống\n            src_data = [line.strip() for line in f_src if line.strip()]\n            trg_data = [line.strip() for line in f_trg if line.strip()]\n        if len(src_data) != len(trg_data):\n             print(f\"Cảnh báo: Số dòng không khớp giữa {src_file} ({len(src_data)}) và {trg_file} ({len(trg_data)}).\")\n             # Giới hạn theo số dòng ít hơn để tránh lỗi zip sau này\n             min_len = min(len(src_data), len(trg_data))\n             src_data = src_data[:min_len]\n             trg_data = trg_data[:min_len]\n        return src_data, trg_data\n    except FileNotFoundError as e:\n        print(f\"Lỗi: Không tìm thấy file: {e}\")\n        return None, None\n    except Exception as e:\n        print(f\"Lỗi khi đọc file: {e}\")\n        return None, None\n\ndef evaluate_model(model, SRC, TRG, device, valid_src_path, valid_trg_path, batch_size=32, max_sentences=None):\n    print(\"--- Bắt đầu quá trình đánh giá ---\")\n\n    # Tải metrics\n    try:\n        bleu_metric = evaluate.load(\"bleu\")\n        rouge_metric = evaluate.load(\"rouge\")\n        print(\"Đã tải xong metrics BLEU và ROUGE.\")\n    except Exception as e:\n        print(f\"Lỗi khi tải metric từ thư viện 'evaluate': {e}\")\n        print(\"Hãy đảm bảo bạn đã cài đặt: pip install evaluate sacrebleu rouge_score\")\n        return None\n\n    # Đọc dữ liệu validation\n    print(f\"Đang đọc dữ liệu validation từ:\\n- Nguồn: {valid_src_path}\\n- Đích: {valid_trg_path}\")\n    src_sentences, ref_sentences = read_data(valid_src_path, valid_trg_path)\n\n    if src_sentences is None or ref_sentences is None:\n        print(\"Không thể tiếp tục đánh giá do lỗi đọc file.\")\n        return None\n\n    print(f\"Đã đọc thành công {len(src_sentences)} câu.\")\n\n    # Giới hạn số câu nếu cần\n    if max_sentences is not None and max_sentences < len(src_sentences):\n        print(f\"Giới hạn đánh giá ở {max_sentences} câu đầu tiên.\")\n        src_sentences = src_sentences[:max_sentences]\n        ref_sentences = ref_sentences[:max_sentences]\n\n    candidates = [] # Lưu các câu dịch được bởi model\n    references = [] # Lưu các câu tham chiếu (có thể là list of lists cho BLEU)\n\n    print(f\"Bắt đầu dịch {len(src_sentences)} câu validation...\")\n    model.eval() # Đảm bảo model ở chế độ đánh giá\n\n    # --- Vòng lặp dịch từng câu ---\n    for i in tqdm(range(len(src_sentences)), desc=\"Đang dịch\"):\n        src_sent = src_sentences[i]\n        ref_sent = ref_sentences[i]\n\n        try:\n            # Gọi hàm dịch của bạn\n            translated_sent = translate_sentence(src_sent, model, SRC, TRG, device, k=opt.get('k', 5), max_len=opt.get('max_strlen', 50)) # Lấy k và max_len từ opt nếu có\n            candidates.append(translated_sent)\n            references.append(ref_sent) # Lưu ref dạng string đơn giản\n\n        except Exception as e:\n            print(f\"\\nCảnh báo: Lỗi khi dịch câu {i+1}: '{src_sent[:50]}...'\")\n            print(f\"  Lỗi: {e}\")\n            # Quyết định xử lý lỗi:\n            # 1. Bỏ qua câu này: continue\n            # 2. Thêm kết quả rỗng để giữ đúng số lượng:\n            candidates.append(\"\") # Thêm chuỗi rỗng\n            references.append(ref_sent) # Vẫn thêm ref tương ứng\n            # 3. Dừng hẳn: raise e\n\n    print(\"Đã dịch xong. Bắt đầu tính toán điểm...\")\n\n    # Định dạng references cho BLEU của thư viện evaluate\n    # Nếu chỉ có 1 ref cho mỗi câu nguồn:\n    references_for_bleu = [[ref] for ref in references]\n\n    # Tính toán điểm\n    try:\n        bleu_score = bleu_metric.compute(predictions=candidates, references=references_for_bleu)\n        # Metric ROUGE thường chấp nhận list of strings cho references\n        rouge_score = rouge_metric.compute(predictions=candidates, references=references)\n\n        print(\"\\n--- Kết quả đánh giá ---\")\n        # BLEU score thường hiển thị dạng 0-100\n        print(f\"BLEU: {bleu_score['bleu'] * 100:.2f}\")\n        # ROUGE scores (thường là F1-score)\n        print(f\"ROUGE-1: {rouge_score['rouge1']:.4f}\")\n        print(f\"ROUGE-2: {rouge_score['rouge2']:.4f}\")\n        print(f\"ROUGE-L: {rouge_score['rougeL']:.4f}\") # Longest common subsequence\n        print(f\"ROUGE-Lsum: {rouge_score['rougeLsum']:.4f}\") # Lsum tóm tắt các câu dài\n        print(\"------------------------\")\n\n        # Trả về dictionary chứa các điểm (BLEU dạng 0-1)\n        results = {\n            'bleu': bleu_score['bleu'],\n            'rouge1': rouge_score['rouge1'],\n            'rouge2': rouge_score['rouge2'],\n            'rougeL': rouge_score['rougeL'],\n            'rougeLsum': rouge_score['rougeLsum']\n        }\n        return results\n\n    except Exception as e:\n        print(f\"\\nLỗi trong quá trình tính toán điểm: {e}\")\n        print(\"Kiểm tra định dạng của candidates và references.\")\n        return None\n\n# Lấy đường dẫn file validation từ dict 'opt' của bạn\nvalid_en_path = opt.get('valid_src_data')\nvalid_vi_path = opt.get('valid_trg_data')\ndevice = opt.get('device', 'cuda' if torch.cuda.is_available() else 'cpu') # Lấy device từ opt hoặc tự xác định\n\nif valid_en_path and valid_vi_path:\n    evaluation_scores = evaluate_model(\n        model=model,\n        SRC=SRC,\n        TRG=TRG,\n        device=device,\n        valid_src_path=valid_en_path,\n        valid_trg_path=valid_vi_path,\n        max_sentences=None # Đặt None để đánh giá toàn bộ tập validation\n    )\n\n    if evaluation_scores:\n        print(\"\\nĐiểm đánh giá chi tiết:\")\n        print(evaluation_scores)\nelse:\n    print(\"Lỗi: Không tìm thấy đường dẫn file validation ('valid_src_data', 'valid_trg_data') trong biến 'opt'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T07:53:21.676219Z","iopub.execute_input":"2025-04-29T07:53:21.676850Z","iopub.status.idle":"2025-04-29T07:55:13.279404Z","shell.execute_reply.started":"2025-04-29T07:53:21.676824Z","shell.execute_reply":"2025-04-29T07:55:13.278723Z"}},"outputs":[{"name":"stdout","text":"--- Bắt đầu quá trình đánh giá ---\nĐã tải xong metrics BLEU và ROUGE.\nĐang đọc dữ liệu validation từ:\n- Nguồn: ./data/valid.en\n- Đích: ./data/valid.vi\nĐã đọc thành công 500 câu.\nBắt đầu dịch 500 câu validation...\n","output_type":"stream"},{"name":"stderr","text":"Đang dịch: 100%|██████████| 500/500 [01:49<00:00,  4.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Đã dịch xong. Bắt đầu tính toán điểm...\n\n--- Kết quả đánh giá ---\nBLEU: 29.37\nROUGE-1: 0.7876\nROUGE-2: 0.6570\nROUGE-L: 0.7442\nROUGE-Lsum: 0.7442\n------------------------\n\nĐiểm đánh giá chi tiết:\n{'bleu': 0.29372343076727364, 'rouge1': 0.7875562682149484, 'rouge2': 0.6570476672441349, 'rougeL': 0.744182961913248, 'rougeLsum': 0.7442248957555513}\n","output_type":"stream"}],"execution_count":42},{"id":"329e3dbc-99f2-4600-b852-ed5f6ec4a4fd","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}